#!/bin/bash
# HAC v5.0 - Home Assistant Context Manager
set -e
HAC_DIR="/config/hac"
OUTPUT_DIR="$HAC_DIR/gist_output"
PACKAGES_DIR="/config/packages"
CONFIG_DIR="/config"
DB_PATH="/config/home-assistant_v2.db"
LEARNINGS_DIR="$HAC_DIR/learnings"
GIST_ID="b8a59919b8f0b71942fc21c10398f9a7"
GITHUB_TOKEN_FILE="$HAC_DIR/.github_token"
GDRIVE_SYNC_PATH="/config/gdrive_sync/hac"

RED='\033[0;31m'; GREEN='\033[0;32m'; YELLOW='\033[1;33m'; BLUE='\033[0;34m'; NC='\033[0m'
log_info() { echo -e "${BLUE}ℹ${NC} $1"; }
log_success() { echo -e "${GREEN}✓${NC} $1"; }
log_warn() { echo -e "${YELLOW}⚠${NC} $1"; }
log_error() { echo -e "${RED}✗${NC} $1"; }

ensure_dirs() { mkdir -p "$OUTPUT_DIR" "$LEARNINGS_DIR" 2>/dev/null || true; }

get_ha_version() {
    curl -s "http://supervisor/core/api/config" -H "Authorization: Bearer $SUPERVISOR_TOKEN" 2>/dev/null | \
    python3 -c "import json,sys; print(json.load(sys.stdin).get('version','unknown'))" 2>/dev/null || echo "unknown"
}

generate_status() {
    cat > "$OUTPUT_DIR/01_status.md" << EOF
# HA Status - $(date '+%Y-%m-%d %H:%M')
Version: $(get_ha_version)

## People
$(curl -s "http://supervisor/core/api/states" -H "Authorization: Bearer $SUPERVISOR_TOKEN" 2>/dev/null | python3 -c "
import json,sys
data=json.load(sys.stdin)
for e in data:
    if e['entity_id'].startswith('person.'):
        print(f\"{e['entity_id'].split('.')[1]}: {e['state']}\")
" 2>/dev/null)

## Modes
$(curl -s "http://supervisor/core/api/states" -H "Authorization: Bearer $SUPERVISOR_TOKEN" 2>/dev/null | python3 -c "
import json,sys
data=json.load(sys.stdin)
for e in data:
    if e['entity_id'].startswith('input_boolean.'):
        name=e['entity_id'].split('.')[1]
        if '_home' in name or '_mode' in name or '_override' in name or name in ['school_tomorrow','guest_present','extended_evening','girls_home','both_girls_home']:
            print(f\"{name}: {e['state']}\")
" 2>/dev/null)

## Triggers (last 20)
$(sqlite3 "$DB_PATH" "SELECT datetime(s.last_updated_ts,'unixepoch','localtime'),replace(m.entity_id,'automation.','') FROM states s JOIN states_meta m ON s.metadata_id=m.metadata_id WHERE m.entity_id LIKE 'automation.%' AND s.state='on' ORDER BY s.last_updated_ts DESC LIMIT 20;" 2>/dev/null)

## Errors (last 10)
$(tail -500 /config/home-assistant.log 2>/dev/null | grep -iE "error|exception" | grep -v "DEBUG\|aiohttp\|httpx" | tail -10)

## Entity Counts
$(curl -s "http://supervisor/core/api/states" -H "Authorization: Bearer $SUPERVISOR_TOKEN" 2>/dev/null | python3 -c "
import json,sys
from collections import Counter
data=json.load(sys.stdin)
for d,c in Counter(e['entity_id'].split('.')[0] for e in data).most_common(15):
    print(f'{c:>6} {d}')
" 2>/dev/null)
EOF
}

generate_health() {
    cat > "$OUTPUT_DIR/05_health.md" << EOF
# System Health - $(date '+%Y-%m-%d %H:%M')

## Integration Status
$(curl -s "http://supervisor/core/api/config/config_entries/entry" -H "Authorization: Bearer $SUPERVISOR_TOKEN" 2>/dev/null | python3 -c "
import json,sys
try:
    data=json.load(sys.stdin)
    failed=[e for e in data if e.get('state') not in ['loaded','not_loaded',None]]
    print('\n'.join([f\"⚠️ {f.get('domain')}: {f.get('state')}\" for f in failed]) if failed else 'All integrations OK')
except: print('Check failed')
" 2>/dev/null)

## Unavailable Entities
$(curl -s "http://supervisor/core/api/states" -H "Authorization: Bearer $SUPERVISOR_TOKEN" 2>/dev/null | python3 -c "
import json,sys
from collections import defaultdict
data=json.load(sys.stdin)
unavail=[e['entity_id'] for e in data if e['state'] in ['unavailable','unknown']]
by_domain=defaultdict(list)
for e in unavail: by_domain[e.split('.')[0]].append(e.split('.')[1])
for d in sorted(by_domain): print(f\"{d}: {len(by_domain[d])} entities\")
print(f'Total: {len(unavail)}')
" 2>/dev/null)

## Automation Status
$(curl -s "http://supervisor/core/api/states" -H "Authorization: Bearer $SUPERVISOR_TOKEN" 2>/dev/null | python3 -c "
import json,sys
data=json.load(sys.stdin)
autos=[e for e in data if e['entity_id'].startswith('automation.')]
disabled=[a for a in autos if a['state']=='off']
print(f'Total: {len(autos)} | Disabled: {len(disabled)}')
" 2>/dev/null)

## Double-Fire Detection (last hour)
$(sqlite3 "$DB_PATH" "SELECT replace(m.entity_id,'automation.',''),COUNT(*) FROM states s JOIN states_meta m ON s.metadata_id=m.metadata_id WHERE m.entity_id LIKE 'automation.%' AND s.state='on' AND s.last_updated_ts>strftime('%s','now','-1 hours') GROUP BY m.entity_id HAVING COUNT(*)>3 ORDER BY COUNT(*) DESC;" 2>/dev/null | while IFS='|' read a f; do echo "⚠️ $a: ${f}x"; done)
EOF
    grep -q "⚠️" "$OUTPUT_DIR/05_health.md" || echo "None detected" >> "$OUTPUT_DIR/05_health.md"
}

generate_packages() {
    echo "# HA Packages - $(date '+%Y-%m-%d %H:%M')" > "$OUTPUT_DIR/02_packages.md"
    echo "All automation packages from /config/packages/" >> "$OUTPUT_DIR/02_packages.md"
    for f in "$PACKAGES_DIR"/*.yaml; do
        [ -f "$f" ] && echo -e "\n## $(basename $f)\n\`\`\`yaml" >> "$OUTPUT_DIR/02_packages.md" && cat "$f" >> "$OUTPUT_DIR/02_packages.md" && echo '```' >> "$OUTPUT_DIR/02_packages.md"
    done
}

generate_knowledge() {
    [ -f "$HAC_DIR/knowledge.md" ] && cp "$HAC_DIR/knowledge.md" "$OUTPUT_DIR/03_knowledge.md" || cat > "$OUTPUT_DIR/03_knowledge.md" << EOF
# System Knowledge - $(date '+%Y-%m-%d %H:%M')
$(cat "$LEARNINGS_DIR"/*.md 2>/dev/null | tail -100 || echo "No learnings")
EOF
}

generate_readme() {
    cat > "$OUTPUT_DIR/00_README.md" << EOF
# Home Assistant Context - John Spencer
**Location:** 40154 US Hwy 53, Strum, WI
**Updated:** $(date '+%Y-%m-%d %H:%M')
**Version:** $(get_ha_version)

## File Index
| File | Contents |
|------|----------|
| 01_status.md | Live status: people, modes, triggers, errors |
| 02_packages.md | All automation YAML from /config/packages/ |
| 03_knowledge.md | System architecture + learnings |
| 05_health.md | Integration health, unavailable, double-fires |

## LLM Rules
1. **Terminal only** - Never suggest GUI actions
2. **&& chaining** - Combine commands efficiently
3. **Propose → Approve → Execute** - Wait for 'yes' before running
4. **Never output secrets/tokens**
5. **Package files** in \`/config/packages/*.yaml\`
6. **Database** at \`/config/home-assistant_v2.db\`

## HAC Commands
| Command | Description |
|---------|-------------|
| \`hac push\` | Sync context to this gist |
| \`hac status\` | System health overview |
| \`hac errors [N]\` | Recent errors |
| \`hac auto\` | List all automations |
| \`hac triggers N\` | Recent automation triggers |
| \`hac learn "note"\` | Add session learning |
| \`hac health\` | Full health report |
EOF
}

sync_to_gist() {
    log_info "Syncing to GitHub Gist..."
    [ ! -f "$GITHUB_TOKEN_FILE" ] && log_error "No GitHub token" && return 1
    local token=$(cat "$GITHUB_TOKEN_FILE")
    local files_json="{"
    local first=true
    for f in "$OUTPUT_DIR"/*.md; do
        [ -f "$f" ] || continue
        local fn=$(basename "$f")
        local content=$(python3 -c "import json,sys; print(json.dumps(open('$f').read()))")
        [ "$first" = true ] && first=false || files_json+=","
        files_json+="\"$fn\":{\"content\":$content}"
    done
    files_json+="}"
    local resp=$(curl -s -X PATCH -H "Authorization: token $token" -H "Accept: application/vnd.github.v3+json" "https://api.github.com/gists/$GIST_ID" -d "{\"files\":$files_json}")
    echo "$resp" | grep -q '"id"' && log_success "Gist synced successfully" || { log_error "Gist sync failed"; return 1; }
}

sync_to_gdrive() {
    [ -d "$GDRIVE_SYNC_PATH" ] && cp "$OUTPUT_DIR"/*.md "$GDRIVE_SYNC_PATH/" 2>/dev/null && log_success "Google Drive synced" || log_warn "GDrive path unavailable"
}

cmd_push() {
    ensure_dirs
    log_info "Generating context files..."
    generate_readme; generate_status; generate_health; generate_packages; generate_knowledge
    log_success "Context files generated"
    sync_to_gist; sync_to_gdrive
    echo ""; echo "═══════════════════════════════════════════════════════════"
    echo "CLAUDE: Fetch these URLs:"
    echo "  https://gist.githubusercontent.com/pigeonfallsrn/$GIST_ID/raw/00_README.md   (start here)"
    echo "  https://gist.githubusercontent.com/pigeonfallsrn/$GIST_ID/raw/01_status.md   (live status)"
    echo "  https://gist.githubusercontent.com/pigeonfallsrn/$GIST_ID/raw/02_packages.md (all automations)"
    echo "  https://gist.githubusercontent.com/pigeonfallsrn/$GIST_ID/raw/03_knowledge.md (system docs)"
    echo "  https://gist.githubusercontent.com/pigeonfallsrn/$GIST_ID/raw/05_health.md   (health report)"
    echo "  https://gist.githubusercontent.com/pigeonfallsrn/$GIST_ID/raw/05_health.md   (health report)"
    echo "═══════════════════════════════════════════════════════════"
    echo "Rules: Terminal only | && chaining | Propose→approve→execute"
    echo "Commands: hac push | hac status | hac health | hac learn \"note\""
    echo "═══════════════════════════════════════════════════════════"
}

cmd_status() {
    echo "=== HA Quick Status ===" && echo "Version: $(get_ha_version)" && echo ""
    echo "People:" && curl -s "http://supervisor/core/api/states" -H "Authorization: Bearer $SUPERVISOR_TOKEN" 2>/dev/null | python3 -c "import json,sys;[print(f\"  {e['entity_id'].split('.')[1]}: {e['state']}\") for e in json.load(sys.stdin) if e['entity_id'].startswith('person.')]" 2>/dev/null
    echo "" && echo "Recent Triggers (5):" && sqlite3 "$DB_PATH" "SELECT datetime(s.last_updated_ts,'unixepoch','localtime'),replace(m.entity_id,'automation.','') FROM states s JOIN states_meta m ON s.metadata_id=m.metadata_id WHERE m.entity_id LIKE 'automation.%' AND s.state='on' ORDER BY s.last_updated_ts DESC LIMIT 5;" 2>/dev/null
}

cmd_errors() { tail -500 /config/home-assistant.log 2>/dev/null | grep -iE "error|exception|fail" | grep -v "DEBUG\|aiohttp" | tail -"${1:-20}"; }

cmd_triggers() { sqlite3 "$DB_PATH" "SELECT datetime(s.last_updated_ts,'unixepoch','localtime'),replace(m.entity_id,'automation.','') FROM states s JOIN states_meta m ON s.metadata_id=m.metadata_id WHERE m.entity_id LIKE 'automation.%' AND s.state='on' ORDER BY s.last_updated_ts DESC LIMIT ${1:-20};" 2>/dev/null; }

cmd_learn() { [ -z "$1" ] && echo "Usage: hac learn \"note\"" && return 1; ensure_dirs; echo "- $(date '+%H:%M'): $1" >> "$LEARNINGS_DIR/$(date '+%Y%m%d').md"; log_success "Learning added"; }

cmd_health() {
    echo "=== Full Health Report ===" && echo ""
    echo "## Integrations" && curl -s "http://supervisor/core/api/config/config_entries/entry" -H "Authorization: Bearer $SUPERVISOR_TOKEN" 2>/dev/null | python3 -c "import json,sys;d=json.load(sys.stdin);f=[e for e in d if e.get('state') not in ['loaded','not_loaded',None]];print('\n'.join([f\"  ⚠️ {x.get('domain')}: {x.get('state')}\" for x in f]) if f else '  All OK')" 2>/dev/null
    echo "" && echo "## Double-Fires (1hr)" && sqlite3 "$DB_PATH" "SELECT replace(m.entity_id,'automation.',''),COUNT(*) FROM states s JOIN states_meta m ON s.metadata_id=m.metadata_id WHERE m.entity_id LIKE 'automation.%' AND s.state='on' AND s.last_updated_ts>strftime('%s','now','-1 hours') GROUP BY m.entity_id HAVING COUNT(*)>3;" 2>/dev/null | while IFS='|' read a f; do echo "  ⚠️ $a: ${f}x"; done
    echo "" && echo "## Config Check" && ha core check 2>&1 | head -3
}

cmd_auto() { curl -s "http://supervisor/core/api/states" -H "Authorization: Bearer $SUPERVISOR_TOKEN" 2>/dev/null | python3 -c "import json,sys;[print(f\"{'✓' if e['state']=='on' else '✗'} {e['attributes'].get('friendly_name',e['entity_id'])}\") for e in sorted(json.load(sys.stdin),key=lambda x:x.get('attributes',{}).get('friendly_name','')) if e['entity_id'].startswith('automation.')]" 2>/dev/null; }

case "${1:-}" in
    push) cmd_push ;; status) cmd_status ;; errors) cmd_errors "${2:-20}" ;; triggers) cmd_triggers "${2:-20}" ;;
    learn) cmd_learn "$2" ;; health) cmd_health ;; auto) cmd_auto ;;
    *) echo "HAC v5.0 - Commands: push|status|health|errors|triggers|auto|learn" ;;
esac
